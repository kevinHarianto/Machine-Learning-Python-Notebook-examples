{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d2d1cf",
   "metadata": {},
   "source": [
    "Answer the following questions using Pandas library. For the submission, please provide the IPython Notebook (ipynb) version with the executed cells. Each question should have its own dedicated cell for clarity and organization.</br>\n",
    "\n",
    "Q1- Read PackageInfo.csv in a Pandas dataframe.</br>\n",
    "Q2- How many rows and columns are in the dataframe?</br>\n",
    "Q3- Remove the columns which their name contains word \"Unnamed\".</br>\n",
    "Q4- Remove all the rows where  a value is missing (contains NAN).</br>\n",
    "Q5- Get list of columns where their type is not integer (int64).</br>\n",
    "Q6- Change the type of columns has numerical value but are in the list of Q5 to int64.</br>\n",
    "Q7- Group the rows by malware? how many groups are there? how many rows are in each group?</br>\n",
    "Q8- Draw a pie chart to visualize the row sizes in the groups from Q7?</br>\n",
    "Q9- Create a new dataframe with columns starting from index 8 and onwards.Print size of its rows and columns in this dataframe.</br>\n",
    "Q10- Create a new dataframe with only the \"malware\" column. Print the number of rows and columns in this dataframe.</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f32ac",
   "metadata": {},
   "source": [
    "# Applying SVM to detect malware versus benign apps.\n",
    "Q11- Use the dataset of Q9 as the featureset</br>\n",
    "Q12- Use the dataset of Q10 as the classes.</br>\n",
    "Q13- Split your data to train and test dataset with the percentage of 80/20.</br>\n",
    "Q14- Apply SVM liner model to train your model.</br>\n",
    "Q15- What are the accuracy, recall, precision, and F-measure values of the trained model when evaluated on the test data</br>\n",
    "Q16- Apply SVM with another kernel other than liner</br>\n",
    "Q17- What are the accuracy, recall, precision, and F-measure values of the new trained model with the alternative kernel when evaluated on the test data? How does it compare to the linear model in terms of performance?</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e6504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
